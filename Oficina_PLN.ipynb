{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Oficina_PLN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhHNl3dgrolY"
      },
      "source": [
        "### Bibliotecas necessárias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg6CLNcCrolb",
        "outputId": "87333220-ea5a-4484-9f51-11c3d846ecc4"
      },
      "source": [
        "# realizando o download e instalação da biblioteca\n",
        "! pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad8ClK9arolc"
      },
      "source": [
        "# importando as bibliotecas necessárias\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import pandas as pd"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9Y62-F5rolc"
      },
      "source": [
        "### Pacotes necessários"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfmF-uoFrolc",
        "outputId": "4e4ed5a4-4e22-4390-9ad9-2239ee0ca037"
      },
      "source": [
        "# importando os pacotes \"stopwords\" e \"punkt\"\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uHi8d-5rold"
      },
      "source": [
        "Use a variável texto a seguir para identificar as stop words\n",
        "e após isso aplique o cáculo do **TF-IDF** neste mesmo texto e observe os scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hR6WEm1wrold"
      },
      "source": [
        "**OBS:** Para realizar essa tarefa utilize os módulos estudados na aula"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfGCIsybrold"
      },
      "source": [
        "# instaciando um texto na variável \"texto\"\n",
        "texto = 'Um carro azul seguia rapidamente em uma rodovia, e ao passar por um buraco, o carro furou o pneu, e o motorista desceu do carro azul'"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cE244H_-sWMx"
      },
      "source": [
        "# instanciando o algoritmo na variável \"stopwords\"\n",
        "# e configurando para o obte-las em português\n",
        "stopwords = nltk.corpus.stopwords.words('portuguese')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSW4sWIrsWLB",
        "outputId": "b79801c3-9eb7-4b24-f81d-fb00030beba1"
      },
      "source": [
        "# para conhecer as stopwords em português vamos imprimi-las\n",
        "print(stopwords)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um', 'para', 'com', 'não', 'uma', 'os', 'no', 'se', 'na', 'por', 'mais', 'as', 'dos', 'como', 'mas', 'ao', 'ele', 'das', 'à', 'seu', 'sua', 'ou', 'quando', 'muito', 'nos', 'já', 'eu', 'também', 'só', 'pelo', 'pela', 'até', 'isso', 'ela', 'entre', 'depois', 'sem', 'mesmo', 'aos', 'seus', 'quem', 'nas', 'me', 'esse', 'eles', 'você', 'essa', 'num', 'nem', 'suas', 'meu', 'às', 'minha', 'numa', 'pelos', 'elas', 'qual', 'nós', 'lhe', 'deles', 'essas', 'esses', 'pelas', 'este', 'dele', 'tu', 'te', 'vocês', 'vos', 'lhes', 'meus', 'minhas', 'teu', 'tua', 'teus', 'tuas', 'nosso', 'nossa', 'nossos', 'nossas', 'dela', 'delas', 'esta', 'estes', 'estas', 'aquele', 'aquela', 'aqueles', 'aquelas', 'isto', 'aquilo', 'estou', 'está', 'estamos', 'estão', 'estive', 'esteve', 'estivemos', 'estiveram', 'estava', 'estávamos', 'estavam', 'estivera', 'estivéramos', 'esteja', 'estejamos', 'estejam', 'estivesse', 'estivéssemos', 'estivessem', 'estiver', 'estivermos', 'estiverem', 'hei', 'há', 'havemos', 'hão', 'houve', 'houvemos', 'houveram', 'houvera', 'houvéramos', 'haja', 'hajamos', 'hajam', 'houvesse', 'houvéssemos', 'houvessem', 'houver', 'houvermos', 'houverem', 'houverei', 'houverá', 'houveremos', 'houverão', 'houveria', 'houveríamos', 'houveriam', 'sou', 'somos', 'são', 'era', 'éramos', 'eram', 'fui', 'foi', 'fomos', 'foram', 'fora', 'fôramos', 'seja', 'sejamos', 'sejam', 'fosse', 'fôssemos', 'fossem', 'for', 'formos', 'forem', 'serei', 'será', 'seremos', 'serão', 'seria', 'seríamos', 'seriam', 'tenho', 'tem', 'temos', 'tém', 'tinha', 'tínhamos', 'tinham', 'tive', 'teve', 'tivemos', 'tiveram', 'tivera', 'tivéramos', 'tenha', 'tenhamos', 'tenham', 'tivesse', 'tivéssemos', 'tivessem', 'tiver', 'tivermos', 'tiverem', 'terei', 'terá', 'teremos', 'terão', 'teria', 'teríamos', 'teriam']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu2mJyNFs4if"
      },
      "source": [
        "**Tokenização**\n",
        "- vamos realizar a tokenização e remover as stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L66MypE8sWJR"
      },
      "source": [
        "# importando a biblioteca\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LslqXlDdsWGK",
        "outputId": "1a842b68-8cdd-48eb-9e7f-946647ea0295"
      },
      "source": [
        "# realizando a divisão da frase criada em tokens\n",
        "tokens = word_tokenize(texto)\n",
        "\n",
        "# imprimindo a tokenização\n",
        "print(tokens)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Um', 'carro', 'azul', 'seguia', 'rapidamente', 'em', 'uma', 'rodovia', ',', 'e', 'ao', 'passar', 'por', 'um', 'buraco', ',', 'o', 'carro', 'furou', 'o', 'pneu', ',', 'e', 'o', 'motorista', 'desceu', 'do', 'carro', 'azul']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iGyJIufdsWDE",
        "outputId": "d8db9e52-5871-4690-9fa2-e31cea2318b0"
      },
      "source": [
        "# realizando um loop simples para imprimir a frase sem os stopwords e melhorar sua visualização\n",
        "for t in tokens:\n",
        "  if t not in stopwords:\n",
        "    print(t)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Um\n",
            "carro\n",
            "azul\n",
            "seguia\n",
            "rapidamente\n",
            "rodovia\n",
            ",\n",
            "passar\n",
            "buraco\n",
            ",\n",
            "carro\n",
            "furou\n",
            "pneu\n",
            ",\n",
            "motorista\n",
            "desceu\n",
            "carro\n",
            "azul\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXAok7sft4RI"
      },
      "source": [
        "Agora vamos utilizar a técnica de cálculo estatístico, `TF-IDF` (do inglês Term Frequency – Inverse Document Frequency) que é muito importante na análise de textos. Pois ela identifica a frequência e a importância que uma palavra para o texto analisado.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWbV8E5SsWBK"
      },
      "source": [
        "# importando a biblioteca\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0Ec7urUsV_G"
      },
      "source": [
        "# instanciando o módulo\n",
        "tf_idf = TfidfVectorizer()"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkLCMhsLu_bb"
      },
      "source": [
        "**Usando o fit_transform**\n",
        "\n",
        "E instanciando numa variável, onde ele retornará uma matriz com os termos e os scores associados, passando o `texto` como contéudo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nG-JoQIsV8A",
        "outputId": "04635ecb-8e79-4159-b54f-1033d5306a54"
      },
      "source": [
        "# aplicando o \".fit_transform\"\n",
        "vetor = tf_idf.fit_transform([texto])\n",
        "\n",
        "# imprimindo a variável\n",
        "print(vetor) # retorna uma matriz com os termos e os scores associados"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 5)\t0.1796053020267749\n",
            "  (0, 4)\t0.1796053020267749\n",
            "  (0, 8)\t0.1796053020267749\n",
            "  (0, 10)\t0.1796053020267749\n",
            "  (0, 7)\t0.1796053020267749\n",
            "  (0, 2)\t0.1796053020267749\n",
            "  (0, 11)\t0.1796053020267749\n",
            "  (0, 9)\t0.1796053020267749\n",
            "  (0, 0)\t0.1796053020267749\n",
            "  (0, 13)\t0.1796053020267749\n",
            "  (0, 16)\t0.1796053020267749\n",
            "  (0, 6)\t0.1796053020267749\n",
            "  (0, 12)\t0.1796053020267749\n",
            "  (0, 14)\t0.1796053020267749\n",
            "  (0, 1)\t0.3592106040535498\n",
            "  (0, 3)\t0.5388159060803247\n",
            "  (0, 15)\t0.3592106040535498\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJhrQ6rGsV4n",
        "outputId": "76a0e962-820d-4b4d-ff0d-ff80ffc2368d"
      },
      "source": [
        "# colocando a matriz em um formato de array\n",
        "vetor = vetor.todense()\n",
        "\n",
        "print(vetor)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.1796053  0.3592106  0.1796053  0.53881591 0.1796053  0.1796053\n",
            "  0.1796053  0.1796053  0.1796053  0.1796053  0.1796053  0.1796053\n",
            "  0.1796053  0.1796053  0.1796053  0.3592106  0.1796053 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCCajOOdsV0a",
        "outputId": "ece9966c-bf29-4bab-c157-1480958eb3bf"
      },
      "source": [
        "# obtendo os nomes das palavras mapeadas\n",
        "nomes  = tf_idf.get_feature_names()\n",
        "\n",
        "# imprimindo a variável\n",
        "print(nomes)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ao', 'azul', 'buraco', 'carro', 'desceu', 'do', 'em', 'furou', 'motorista', 'passar', 'pneu', 'por', 'rapidamente', 'rodovia', 'seguia', 'um', 'uma']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YoCnSOiPvW01",
        "outputId": "14c83567-d54a-4a5c-fd71-08ad70d706da"
      },
      "source": [
        "# associando os scores aos nomes das palavras e o resultado em um dataframe\n",
        "df = pd.DataFrame(vetor, columns=nomes)\n",
        "print(df)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         ao      azul    buraco  ...    seguia        um       uma\n",
            "0  0.179605  0.359211  0.179605  ...  0.179605  0.359211  0.179605\n",
            "\n",
            "[1 rows x 17 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wf1HL8QxPcY",
        "outputId": "99a16305-c70d-4115-89df-885b54a68162"
      },
      "source": [
        "df.max()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ao             0.179605\n",
              "azul           0.359211\n",
              "buraco         0.179605\n",
              "carro          0.538816\n",
              "desceu         0.179605\n",
              "do             0.179605\n",
              "em             0.179605\n",
              "furou          0.179605\n",
              "motorista      0.179605\n",
              "passar         0.179605\n",
              "pneu           0.179605\n",
              "por            0.179605\n",
              "rapidamente    0.179605\n",
              "rodovia        0.179605\n",
              "seguia         0.179605\n",
              "um             0.359211\n",
              "uma            0.179605\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brWFOEnpxn5D"
      },
      "source": [
        "**Perceba que, a palavra com maior importância é** `\"carro\"`**, com score de** `0.538816` **e, as seguintes palavras são** `\"azul\"` **e** `\"um\"` **com scores de** `0.359211`**.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUL2QfQwvWyW"
      },
      "source": [
        "# df.values"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-TuqEzYvWrB"
      },
      "source": [
        "# df.columns"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "priDtVyyvWcK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVuoCiE-vWYZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poAtxGdjvWU2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clXmAdgIvWSp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeU6SxIlvWOc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}